{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes on \"Representation learning of speech data by mutual information maximization\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this repository, I share the codes and notes on \"representation learning of speech data by mutual information maximization\".\n",
    "\n",
    "I refer to [\"Representation learning by contrastive predictive coding\"](https://arxiv.org/abs/1807.03748) and [\"Wasserstein Dependency Measure for Representation Learning\"](https://arxiv.org/abs/1903.11780) for more details on theoretical backgrounds. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To summarize, I used the following ideas.\n",
    "* To minimize the surrogate form of mutual information between two representations.\n",
    "* It is formulized by predicting \"the local representation at future $t+k$-th step with \"the global representation at $t$-th step.\n",
    "* The first infoNCE loss is propsed by [Aaron van der Oord et. al.](https://arxiv.org/abs/1807.03748). Further to this, the infoNCE loss, which is also termed as the contrastive predictive coding (CPC) loss, is reformulized by enforcing 1-Lipscthiz continuity on the kind of critic function used to predict future representations and this new loss proposed by [Sherjil Ozair et. al.](https://arxiv.org/abs/1903.11780) is called as the Wasserstein predictive coding (WPC) loss.\n",
    "\n",
    "I next discuss the methodology and the results on this small personal project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methodology"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](predictive_coding.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As shown in the above figure,\n",
    "* A set of input speech data is given to the model. The window size of the inputs is 20480(=128x160).\n",
    "* Then, the convolutional encoder and the GRU-RNN blocks produce $z_t$ and $c_t$, respectively.\n",
    "* As described in the paper, the convolutional encoder is composed of five convolutional layers with strides=[5,4,2,2,2], filter_size=[10,8,4,4,4] and hidden dimension=512. Therefore, the down-sampling factor of this encoder is 160(=5x4x2x2x2), and the output with shape [batch_size, 128, 512] (corresdponds to a set of $z_t$ will be obtained from the encoder.\n",
    "* The GRU-RNN sequentially reads $z_t$ and produces $c_t$ with its hidden dimension=512.\n",
    "* We can understand that $z_t$ is a local vector contains the local information of the sensory inputs with window size 160, and $c_t$ is a vector contains the global information before the $t$-th step.\n",
    "* This model aims to learn both local and global representations (latent vectors) by minimizing the infoNCE loss. [Aaron van der Oord et. al.](https://arxiv.org/abs/1807.03748) propose to optimize the following objective:\n",
    "$$\n",
    "\\mathcal{L}_{CPC}(c_t, z_{t+k}, \\{\\tilde{z}_{t+k}\\}) = \\sup_{f \\in \\mathcal{F}}  \\mathbb{E}_{p(c_{t}, z_{t+k})}[f(c_t, z_{t+k})] - \\mathbb{E}_{p(c_{t})p(\\tilde{z}_{j,t+k})}[\\log \\sum_j \\exp f(c_t, \\tilde{z}_{j,t+k})],\n",
    "$$\n",
    "where $f(c_{t}, z_{t+k}) = c_{t}^T W_k z_{t+k} $, $z_{t+k}$ is the positive samples and $\\tilde{z}_{j, t+k}$ is the negative samples both at $t+k$ step. Optimizing this objective performs \\textbf{predicting the postive samples from the mixture of positive and negtiave samples by using the global representation $c_t$ at $t$-th step.\n",
    "* [Sherjil Ozair et. al.](https://arxiv.org/abs/1903.11780) modifies the firstly proposed CPC loss by enforcing the 1-Lipscthiz continuity on the critic function $W_k$.\n",
    "$$\n",
    "\\mathcal{L}_{WPC}(c_t, z_{t+k}, \\{\\tilde{z}_{t+k}\\}) = \\sup_{f \\in \\mathcal{F}_{1-Lipschitz}}  \\mathbb{E}_{p(c_{t}, z_{t+k})}[f(c_t, z_{t+k})] - \\mathbb{E}_{p(c_{t})p(\\tilde{z}_{j,t+k})}[\\log \\sum_j \\exp f(c_t, \\tilde{z}_{j,t+k})],\n",
    "$$\n",
    "where $\\mathcal{F}_{1-Lipschitz}$ is the family of the critic functions satisfying 1-Lipscthiz continuity. The idea comes from measuing Wasserstien-1 distance, not KL-divernce, between the joint and the product of marginal distributions on $z_{t}$ and $c_{t+k}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments\n",
    "1. Representation learning of speech data\n",
    "![](loss_plot.png)\n",
    "\n",
    "Firstly, I pre-trained the encoder and the GRU-RNN by minimizing the CPC/WPC loss. \n",
    "The above figure shows the change of CPCand WPC losses as the training epoch increases. \n",
    "We can confirm that the WPC loss is slightly lower than the CPC loss.\n",
    "\n",
    "2. Semi-supervised learning with learned representations\n",
    "![](supervised.jpg)\n",
    "\n",
    "Next, I planned to verify the quality of the representations leanred by minimizing the CPC/WPC losses. \n",
    "Firstly, I summarized the ${c_t}_{t=1}^{128}$ by global-average pooling and trained the linear-classifier to predict the speakers. \n",
    "Total 251 classes of speaker labels are given. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](accuracy_plot.png)\n",
    "As can be shown in the above figure, using the pre-trained models greatly outperform the purely supervised learning model. Also, representations obtained by minimizing the WPC is better than that by minimizing the CPC loss in the prediction task. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Future Direction\n",
    "\n",
    "Learning representations by mutual information maximization, which is especially formalized by predicting future contexts from past contexts, shows good performances on the speaker classification of LibriSpeech data. \n",
    "\n",
    "I expect that the representation learning by predictive coding and mutual information maximization would be powerful on other domains, such as images, medical records, molecular graphs and financial time series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
